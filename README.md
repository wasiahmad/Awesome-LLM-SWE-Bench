# LLMs for SWE-Bench: Solving Real-World GitHub Issues
A reading list on large language models solving real-world GitHub issues.

<div align="center">

[![LICENSE](https://img.shields.io/github/license/wasiahmad/Awesome-LLM-SWE-Bench)](https://github.com/wasiahmad/Awesome-LLM-SWE-Bench/blob/main/LICENSE)
![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)
[![commit](https://img.shields.io/github/last-commit/wasiahmad/Awesome-LLM-SWE-Bench?color=blue)](https://github.com/wasiahmad/Awesome-LLM-SWE-Bench/commits/main)
[![PR](https://img.shields.io/badge/PRs-Welcome-red)](https://github.com/wasiahmad/Awesome-LLM-SWE-Bench/pulls)
[![GitHub Repo stars](https://img.shields.io/github/stars/wasiahmad/Awesome-LLM-SWE-Bench)](https://github.com/wasiahmad/Awesome-LLM-SWE-Bench)
<!-- ![license](https://img.shields.io/bower/l/bootstrap?style=plastic) -->

</div>

This repo includes papers, tools, and blogs about LLMs for SWE-Bench.

Thanks for all the great contributors on GitHub!ðŸ”¥âš¡ðŸ”¥

## Contents

- [1. Benchmarks](#1-benchmarks)
- [2. Methods/Datasets](#2-methods-datasets)
- [3. Tools](#3-tools)
- [4. Blogs](#4-blogs)

## 1. Benchmarks
- **SWE-bench: Can Language Models Resolve Real-World GitHub Issues?** <br> 
  *Jimenez et al., 2024* [[Paper](https://arxiv.org/abs/2310.06770)][[GitHub](https://github.com/SWE-bench/SWE-bench/tree/main)] [[Leaderboard](https://www.swebench.com/)][[Dataset](https://huggingface.co/datasets/princeton-nlp/SWE-bench)] <br>

- [SWE-bench Multimodal: Do AI Systems Generalize to Visual Software Domains?](https://arxiv.org/abs/2410.03859)<br>
  *Yang et al., 2024* [[GitHub](https://github.com/SWE-bench/SWE-bench/tree/main)] [[Leaderboard](https://www.swebench.com/multimodal.html)]
- [SWE-bench Multilingual](https://kabirk.com/multilingual)<br>
  *Khandpur et al., 2024* [[GitHub](https://github.com/SWE-bench/SWE-bench/tree/main)][[Dataset](https://huggingface.co/datasets/SWE-bench/SWE-bench_Multilingual)]
- [Multi-SWE-bench: A Multilingual Benchmark for Issue Resolving](https://arxiv.org/pdf/2504.02605)<br>
  *Zan et al., 2025* [[GitHub](https://github.com/multi-swe-bench/multi-swe-bench)] [[Leaderboard](https://multi-swe-bench.github.io/)]
- [SWE-PolyBench: A Multi-language Benchmark for Repository Level Evaluation of Coding Agents](https://arxiv.org/abs/2504.08703)<br>
  *Rashid et al., 2025* [[GitHub](https://github.com/amazon-science/SWE-PolyBench)][[Leaderboard](https://amazon-science.github.io/SWE-PolyBench/)][[Dataset](https://huggingface.co/datasets/AmazonScience/SWE-PolyBench)]
- [SWE-bench Goes Live!](https://arxiv.org/abs/2505.23419)<br>
  *Zhang et al., 2025* [[GitHub](https://github.com/microsoft/SWE-bench-Live)][[Leaderboard](https://swe-bench-live.github.io/)][[Dataset](https://huggingface.co/datasets/SWE-bench-Live/SWE-bench-Live)]

## 2. Methods/Datasets
- [SWE-Fixer: Training Open-Source LLMs for Effective and Efficient GitHub Issue Resolution](https://arxiv.org/abs/2501.05040)<br>
  *Xie et al., 2025* [[GitHub](https://github.com/InternLM/SWE-Fixer)]
- [SWE-smith: Scaling Data for Software Engineering Agents](https://arxiv.org/abs/2504.21798)
  *Yang et al., 2025* [[GitHub](https://github.com/SWE-bench/SWE-smith)][[Webpage](https://swesmith.com/)]

## 3. Tools


## 4. Blogs

- [Raising the bar on SWE-bench Verified with Claude 3.5 Sonnet](https://www.anthropic.com/engineering/swe-bench-sonnet)<br>
  *Engineering at Anthropic, 2025*


